{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39717, 111)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we add the parameter `low_memory=False` since pandas reads data from files in chunks by default.\n",
    "# pandas also tries its best to decide on the `dtype` of the data in the chunk.\n",
    "# what happened here was that another chunk turned out to be a different dtype.\n",
    "# now we have 2 options, either we manually let pandas know the `dtype` or we let pandas pull the entire dataset in memory and decide\n",
    "# since there is enough ram on this machin to pull the entire data, we took the option of using `low_memory=False`\n",
    "inp0 = pd.read_csv('loan.csv', low_memory=False)\n",
    "inp0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* there are about 39k rows and 111 columns\n",
    "* 111 columns are going to be too hard to work with for EDA so we need to find our columns which will be the drop candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning - part 1\n",
    "* identify empty columns and drop them\n",
    "* identify empty rows and drop them\n",
    "* de-duplicate the entire data\n",
    "* identify columns with a single categorical value and drop them\n",
    "* identify other irrelevant columns, like long text, non-url-part-urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### identify empty columns and drop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n",
      "mths_since_last_record         36931\n",
      "next_pymnt_d                   38577\n",
      "mths_since_last_major_derog    39717\n",
      "annual_inc_joint               39717\n",
      "dti_joint                      39717\n",
      "dtype: int64\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "temp = inp0.isnull() # this gives a dataframe with all cells as true/false. true if its empty/nan/null\n",
    "temp = temp.sum() # sum() has a default parameter of axis=0 which will sum over a column. remember `True` == 1\n",
    "temp = temp[temp > 35000] # we choose all columns which have about 35k out of 39k missing values in their rows\n",
    "print(temp.size) # 56 of them have more than 35k rows with missing values, it's good to drop them\n",
    "print(temp.head())\n",
    "drop_column_candidates = temp.index.to_list()\n",
    "print(type(drop_column_candidates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39717, 55)\n"
     ]
    }
   ],
   "source": [
    "# we do not want to change the raw input, so we take a copy to another variable, this also makes this cell idempotent\n",
    "inp1 = inp0.drop(columns=drop_column_candidates).copy()\n",
    "print(inp1.shape) # we have about 55 remaining columns for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39717, 53)\n"
     ]
    }
   ],
   "source": [
    "# not idempotent\n",
    "# lets check for a few more columns which have good amount of missing values\n",
    "# let's check how many remaining columns have more than 50% missing values\n",
    "100*inp1.isnull().mean()\n",
    "# we see that `desc` column has about 32% missing values and `mths_since_last_delinq` has about 64, we can handpick them and drop them\n",
    "# it's ok to drop `desc` which is the description of the loan, since we are not going to do any NLP.\n",
    "inp1.drop(columns = ['desc', 'mths_since_last_delinq'], inplace=True) # we do an inplace drop here since inp1 is just an output of dropped columns from the original raw data.\n",
    "print(inp1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* at this point we do not have columns with a lot of missing values. The columns with a few missing values will be treated a little later, first we need to identify the rows with a lot of missing values, let's go ahead and do that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### identify empty rows and drop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3286, 53)\n"
     ]
    }
   ],
   "source": [
    "temp = inp1.isnull().mean(axis=1)*100 > 1.0\n",
    "print(inp1[temp].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* we observe that only 10%(of 39k) rows have 1%(of 53) columns missing, which is a pretty good dataset. not a lot of rows to remove.\n",
    "* let's make an attempt to de-duplicate the data at this point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39717, 53)\n",
      "(39717, 53)\n"
     ]
    }
   ],
   "source": [
    "print(inp1.shape)\n",
    "print(inp1.drop_duplicates().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* we observe that at this point there are no duplicate rows "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### identify columns with a single value and drop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pymnt_plan                    1\n",
      "initial_list_status           1\n",
      "collections_12_mths_ex_med    1\n",
      "policy_code                   1\n",
      "application_type              1\n",
      "acc_now_delinq                1\n",
      "chargeoff_within_12_mths      1\n",
      "delinq_amnt                   1\n",
      "tax_liens                     1\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pymnt_plan</th>\n",
       "      <th>initial_list_status</th>\n",
       "      <th>collections_12_mths_ex_med</th>\n",
       "      <th>policy_code</th>\n",
       "      <th>application_type</th>\n",
       "      <th>acc_now_delinq</th>\n",
       "      <th>chargeoff_within_12_mths</th>\n",
       "      <th>delinq_amnt</th>\n",
       "      <th>tax_liens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39712</th>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39713</th>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39714</th>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39715</th>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39716</th>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39717 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pymnt_plan initial_list_status  collections_12_mths_ex_med  policy_code  \\\n",
       "0              n                   f                         0.0            1   \n",
       "1              n                   f                         0.0            1   \n",
       "2              n                   f                         0.0            1   \n",
       "3              n                   f                         0.0            1   \n",
       "4              n                   f                         0.0            1   \n",
       "...          ...                 ...                         ...          ...   \n",
       "39712          n                   f                         NaN            1   \n",
       "39713          n                   f                         NaN            1   \n",
       "39714          n                   f                         NaN            1   \n",
       "39715          n                   f                         NaN            1   \n",
       "39716          n                   f                         NaN            1   \n",
       "\n",
       "      application_type  acc_now_delinq  chargeoff_within_12_mths  delinq_amnt  \\\n",
       "0           INDIVIDUAL               0                       0.0            0   \n",
       "1           INDIVIDUAL               0                       0.0            0   \n",
       "2           INDIVIDUAL               0                       0.0            0   \n",
       "3           INDIVIDUAL               0                       0.0            0   \n",
       "4           INDIVIDUAL               0                       0.0            0   \n",
       "...                ...             ...                       ...          ...   \n",
       "39712       INDIVIDUAL               0                       NaN            0   \n",
       "39713       INDIVIDUAL               0                       NaN            0   \n",
       "39714       INDIVIDUAL               0                       NaN            0   \n",
       "39715       INDIVIDUAL               0                       NaN            0   \n",
       "39716       INDIVIDUAL               0                       NaN            0   \n",
       "\n",
       "       tax_liens  \n",
       "0            0.0  \n",
       "1            0.0  \n",
       "2            0.0  \n",
       "3            0.0  \n",
       "4            0.0  \n",
       "...          ...  \n",
       "39712        NaN  \n",
       "39713        NaN  \n",
       "39714        NaN  \n",
       "39715        NaN  \n",
       "39716        NaN  \n",
       "\n",
       "[39717 rows x 9 columns]"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = inp1.nunique() # gives unique count of all the columns\n",
    "unique_condition_1 = temp == 1 # which columns have just 1 unique value\n",
    "temp = temp[unique_condition_1]\n",
    "print(temp)\n",
    "# let's verify the column data once for unique_condition_1 column\n",
    "inp1[temp.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39717, 44)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = inp1.nunique() # gives unique count of all the columns\n",
    "unique_condition_1 = temp == 1 # which columns have just 1 unique value\n",
    "temp = temp[unique_condition_1]\n",
    "inp1 = inp1.drop(columns = temp.index)\n",
    "inp1.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### identify other irrelevant columns, like long text, non-url-part-urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp1 = inp1.drop(columns=['title']) # we will not do any NLP\n",
    "inp1 = inp1.drop(columns=['url']) # there is no special url part available, all the URLs only differ by the loan id\n",
    "inp1 = inp1.drop(columns=['member_id']) # since there is no repeated member"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39717, 41)\n",
      "(39717, 41)\n"
     ]
    }
   ],
   "source": [
    "# let's check for de-duplicacy again\n",
    "print(inp1.shape)\n",
    "print(inp1.drop_duplicates().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning - part 2\n",
    "* treating missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### treating missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "last_credit_pull_d      0.005036\n",
       "revol_util              0.125891\n",
       "last_pymnt_d            0.178765\n",
       "pub_rec_bankruptcies    1.754916\n",
       "emp_length              2.706650\n",
       "emp_title               6.191303\n",
       "dtype: float64"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = 100*inp1.isnull().mean()\n",
    "# there are 53 columns, we just want to see the columns which have missing values\n",
    "missing_value_condition = temp > 0.0\n",
    "temp[missing_value_condition].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* since all these rows are less than 10%, let's remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39717, 41)\n",
      "(36442, 41)\n"
     ]
    }
   ],
   "source": [
    "print(inp1.shape)\n",
    "inp1 = inp1[~inp1['last_credit_pull_d'].isnull()]\n",
    "inp1 = inp1[~inp1['revol_util'].isnull()]\n",
    "inp1 = inp1[~inp1['last_pymnt_d'].isnull()]\n",
    "inp1 = inp1[~inp1['pub_rec_bankruptcies'].isnull()]\n",
    "inp1 = inp1[~inp1['emp_length'].isnull()]\n",
    "inp1 = inp1[~inp1['emp_title'].isnull()]\n",
    "print(inp1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial shape = (39717, 111)\n",
      "shape after cleaning = (36442, 41)\n",
      "data loss after cleaning = 8%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], dtype: float64)"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'initial shape = {inp0.shape}')\n",
    "print(f'shape after cleaning = {inp1.shape}')\n",
    "print(f'data loss after cleaning = {round (100*(inp0.shape[0]-inp1.shape[0])/inp0.shape[0])}%')\n",
    "\n",
    "temp = 100*inp1.isnull().mean()\n",
    "missing_value_condition = temp > 0.0\n",
    "temp[missing_value_condition].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* we still have 92% data without any missing values, which looks like a good dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expanding Datetime columns\n",
    "* We will find all date columns and expand them to year/month/day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'loan_amnt', 'funded_amnt', 'funded_amnt_inv', 'term', 'int_rate',\n",
      "       'installment', 'grade', 'sub_grade', 'emp_title', 'emp_length',\n",
      "       'home_ownership', 'annual_inc', 'verification_status', 'issue_d',\n",
      "       'loan_status', 'purpose', 'zip_code', 'addr_state', 'dti',\n",
      "       'delinq_2yrs', 'earliest_cr_line', 'inq_last_6mths', 'open_acc',\n",
      "       'pub_rec', 'revol_bal', 'revol_util', 'total_acc', 'out_prncp',\n",
      "       'out_prncp_inv', 'total_pymnt', 'total_pymnt_inv', 'total_rec_prncp',\n",
      "       'total_rec_int', 'total_rec_late_fee', 'recoveries',\n",
      "       'collection_recovery_fee', 'last_pymnt_d', 'last_pymnt_amnt',\n",
      "       'last_credit_pull_d', 'pub_rec_bankruptcies'],\n",
      "      dtype='object')\n",
      "[' 60 months' ' 36 months']\n",
      "[60 36]\n",
      "[60 36]\n",
      "Index(['id', 'loan_amnt', 'funded_amnt', 'funded_amnt_inv', 'term_months',\n",
      "       'int_rate', 'installment', 'grade', 'sub_grade', 'emp_title',\n",
      "       'emp_length', 'home_ownership', 'annual_inc', 'verification_status',\n",
      "       'issue_d', 'loan_status', 'purpose', 'zip_code', 'addr_state', 'dti',\n",
      "       'delinq_2yrs', 'earliest_cr_line', 'inq_last_6mths', 'open_acc',\n",
      "       'pub_rec', 'revol_bal', 'revol_util', 'total_acc', 'out_prncp',\n",
      "       'out_prncp_inv', 'total_pymnt', 'total_pymnt_inv', 'total_rec_prncp',\n",
      "       'total_rec_int', 'total_rec_late_fee', 'recoveries',\n",
      "       'collection_recovery_fee', 'last_pymnt_d', 'last_pymnt_amnt',\n",
      "       'last_credit_pull_d', 'pub_rec_bankruptcies'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(inp1.columns)\n",
    "\n",
    "# term\n",
    "print(inp1['term'].unique())\n",
    "inp1['term'] = inp1['term'].str.strip().str.replace(' months', '').astype(int)\n",
    "inp1.rename(columns={\"term\": \"term_months\"}, inplace=True)\n",
    "print(inp1['term_months'].unique())\n",
    "\n",
    "print(inp1.columns)\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['addr_state', 'annual_inc', 'collection_recovery_fee', 'delinq_2yrs',\n",
       "       'dti', 'earliest_cr_line', 'emp_length', 'emp_title', 'funded_amnt',\n",
       "       'funded_amnt_inv', 'grade', 'home_ownership', 'id', 'inq_last_6mths',\n",
       "       'installment', 'int_rate', 'issue_d', 'issue_d_month', 'issue_d_year',\n",
       "       'last_credit_pull_d', 'last_pymnt_amnt', 'last_pymnt_d', 'loan_amnt',\n",
       "       'loan_status', 'open_acc', 'out_prncp', 'out_prncp_inv', 'pub_rec',\n",
       "       'pub_rec_bankruptcies', 'purpose', 'recoveries', 'revol_bal',\n",
       "       'revol_util', 'sub_grade', 'term_months', 'total_acc', 'total_pymnt',\n",
       "       'total_pymnt_inv', 'total_rec_int', 'total_rec_late_fee',\n",
       "       'total_rec_prncp', 'verification_status', 'zip_code'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# issue_d\n",
    "inp1['issue_d'].unique()\n",
    "inp1['issue_d'] = pd.to_datetime(inp1['issue_d'], format='%b-%y')\n",
    "inp1['issue_d_month'] = inp1['issue_d'].dt.month\n",
    "inp1['issue_d_year'] = inp1['issue_d'].dt.year\n",
    "\n",
    "inp1.columns.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['addr_state', 'annual_inc', 'collection_recovery_fee', 'delinq_2yrs',\n",
       "       'dti', 'earliest_cr_line', 'emp_length', 'emp_title', 'funded_amnt',\n",
       "       'funded_amnt_inv', 'grade', 'home_ownership', 'id', 'inq_last_6mths',\n",
       "       'installment', 'int_rate', 'issue_d', 'issue_d_month', 'issue_d_year',\n",
       "       'last_credit_pull_d', 'last_credit_pull_d_month',\n",
       "       'last_credit_pull_d_year', 'last_pymnt_amnt', 'last_pymnt_d',\n",
       "       'loan_amnt', 'loan_status', 'open_acc', 'out_prncp', 'out_prncp_inv',\n",
       "       'pub_rec', 'pub_rec_bankruptcies', 'purpose', 'recoveries', 'revol_bal',\n",
       "       'revol_util', 'sub_grade', 'term_months', 'total_acc', 'total_pymnt',\n",
       "       'total_pymnt_inv', 'total_rec_int', 'total_rec_late_fee',\n",
       "       'total_rec_prncp', 'verification_status', 'zip_code'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# last_credit_pull_d\n",
    "\n",
    "inp1['last_credit_pull_d'] = pd.to_datetime(inp1['last_credit_pull_d'], format = '%b-%y')\n",
    "inp1['last_credit_pull_d_month'] = inp1['last_credit_pull_d'].dt.month\n",
    "inp1['last_credit_pull_d_year'] = inp1['last_credit_pull_d'].dt.year\n",
    "\n",
    "inp1.columns.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['addr_state', 'annual_inc', 'collection_recovery_fee', 'delinq_2yrs',\n",
       "       'dti', 'earliest_cr_line', 'emp_length', 'emp_title', 'funded_amnt',\n",
       "       'funded_amnt_inv', 'grade', 'home_ownership', 'id', 'inq_last_6mths',\n",
       "       'installment', 'int_rate', 'issue_d', 'issue_d_month', 'issue_d_year',\n",
       "       'last_credit_pull_d', 'last_credit_pull_d_month',\n",
       "       'last_credit_pull_d_year', 'last_pymnt_amnt', 'last_pymnt_d',\n",
       "       'last_pymnt_d_month', 'last_pymnt_d_year', 'loan_amnt', 'loan_status',\n",
       "       'open_acc', 'out_prncp', 'out_prncp_inv', 'pub_rec',\n",
       "       'pub_rec_bankruptcies', 'purpose', 'recoveries', 'revol_bal',\n",
       "       'revol_util', 'sub_grade', 'term_months', 'total_acc', 'total_pymnt',\n",
       "       'total_pymnt_inv', 'total_rec_int', 'total_rec_late_fee',\n",
       "       'total_rec_prncp', 'verification_status', 'zip_code'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# last_pymnt_d\n",
    "\n",
    "inp1['last_pymnt_d'] = pd.to_datetime(inp1['last_pymnt_d'], format = '%b-%y')\n",
    "inp1['last_pymnt_d_month'] = inp1['last_pymnt_d'].dt.month\n",
    "inp1['last_pymnt_d_year'] = inp1['last_pymnt_d'].dt.year\n",
    "\n",
    "inp1.columns.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Univariate analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
